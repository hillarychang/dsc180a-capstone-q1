{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e77a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inflows = pd.read_parquet(\"Data/ucsd-inflows.pqt\")\n",
    "outflows = pd.read_parquet(\"Data/ucsd-outflows.pqt\")\n",
    "import re\n",
    "\n",
    "def clean_text(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    # create the patterns\n",
    "\n",
    "    # pattern1 handles the dates, and the states \n",
    "    pattern1 = r'\\b(?:CA\\s+)?(?:0?[1-9]|1[0-2])[/-](?:0?[1-9]|[12]\\d|3[01])(?:/\\d{2,4})?\\b'\n",
    "\n",
    "    # pattern2 handles unnecessary X's\n",
    "    pattern2 = r'(?<!#)XX+|#XX+'\n",
    "\n",
    "    # Handles unnecessary punctuation\n",
    "    pattern3 = r\"[^a-zA-Z0-9\\s./]\"\n",
    "\n",
    "    # get rid of the state at the end of the wording\n",
    "    pattern4 = r'\\s[A-Z]{2}$'\n",
    "\n",
    "    # Handles \"POS WITHDRAWAL | DEBIT CARD WITHDRAWL\"\n",
    "    pattern5 = r'(pos withdrawal|debit card withdrawal)'\n",
    "\n",
    "    # handles the word \"purchase\"\n",
    "    pattern6 = r'(purchase)'\n",
    "\n",
    "    # make everything lower case, and get rid of unnecessary spacing between words\n",
    "    df['memo'] = df['memo'].apply(lambda x: re.sub(pattern3, '', re.sub(pattern2, '', re.sub(pattern1, '', x))))\n",
    "    df['memo'] = df['memo'].apply(lambda x: \" \".join(x.split()).strip())\n",
    "    df['memo'] = df['memo'].apply(lambda x: re.sub(pattern4, '', x))\n",
    "    df[\"memo\"] = df[\"memo\"].apply(lambda x: re.sub(pattern6, '', re.sub(pattern5, '', x.lower())))\n",
    "    return df\n",
    "not_matching = outflows[outflows['memo'] != outflows['category']]\n",
    "cleaned_not_matching = clean_text(not_matching)\n",
    "#cleaned_inflows = clean_text(inflows)\n",
    "#cleaned_outflows = clean_text(outflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628baa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>tst casa del rio exp fairlawn</td>\n",
       "      <td>18.42</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>buffalo wild wings</td>\n",
       "      <td>26.47</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>oculus</td>\n",
       "      <td>11.73</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>los girasoles stow</td>\n",
       "      <td>30.04</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>buzzis laundry 1</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597457</th>\n",
       "      <td>5941</td>\n",
       "      <td>acc_9524</td>\n",
       "      <td>amazon primeti40l27r3 amzn.com/bill wa date p...</td>\n",
       "      <td>15.93</td>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597462</th>\n",
       "      <td>5941</td>\n",
       "      <td>acc_9524</td>\n",
       "      <td>az lot quiktrip e indian school rd phoeni az c...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597465</th>\n",
       "      <td>5941</td>\n",
       "      <td>acc_9524</td>\n",
       "      <td>walmart e mckellips rd mesa az card 15 mcc</td>\n",
       "      <td>3.68</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597468</th>\n",
       "      <td>5941</td>\n",
       "      <td>acc_9524</td>\n",
       "      <td>withdrawal salt river projetype online pmt cos...</td>\n",
       "      <td>90.00</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597476</th>\n",
       "      <td>5941</td>\n",
       "      <td>acc_9524</td>\n",
       "      <td>frysfooddrg 1 435 s. e mesa az card 15 mcc</td>\n",
       "      <td>7.74</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306452 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prism_consumer_id prism_account_id  \\\n",
       "2                        0            acc_0   \n",
       "4                        0            acc_0   \n",
       "6                        0            acc_0   \n",
       "7                        0            acc_0   \n",
       "8                        0            acc_0   \n",
       "...                    ...              ...   \n",
       "2597457               5941         acc_9524   \n",
       "2597462               5941         acc_9524   \n",
       "2597465               5941         acc_9524   \n",
       "2597468               5941         acc_9524   \n",
       "2597476               5941         acc_9524   \n",
       "\n",
       "                                                      memo  amount  \\\n",
       "2                            tst casa del rio exp fairlawn   18.42   \n",
       "4                                       buffalo wild wings   26.47   \n",
       "6                                                   oculus   11.73   \n",
       "7                                       los girasoles stow   30.04   \n",
       "8                                         buzzis laundry 1    4.16   \n",
       "...                                                    ...     ...   \n",
       "2597457   amazon primeti40l27r3 amzn.com/bill wa date p...   15.93   \n",
       "2597462  az lot quiktrip e indian school rd phoeni az c...   25.00   \n",
       "2597465         walmart e mckellips rd mesa az card 15 mcc    3.68   \n",
       "2597468  withdrawal salt river projetype online pmt cos...   90.00   \n",
       "2597476         frysfooddrg 1 435 s. e mesa az card 15 mcc    7.74   \n",
       "\n",
       "        posted_date             category  \n",
       "2        2022-09-26   FOOD_AND_BEVERAGES  \n",
       "4        2022-09-12   FOOD_AND_BEVERAGES  \n",
       "6        2022-04-18  GENERAL_MERCHANDISE  \n",
       "7        2022-03-09   FOOD_AND_BEVERAGES  \n",
       "8        2022-03-29  GENERAL_MERCHANDISE  \n",
       "...             ...                  ...  \n",
       "2597457  2023-01-16  GENERAL_MERCHANDISE  \n",
       "2597462  2023-01-18            EDUCATION  \n",
       "2597465  2023-01-18   FOOD_AND_BEVERAGES  \n",
       "2597468  2023-01-20   FOOD_AND_BEVERAGES  \n",
       "2597476  2023-01-21   FOOD_AND_BEVERAGES  \n",
       "\n",
       "[1306452 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_not_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae47eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_cleaned_inflows = cleaned_inflows.copy()  \n",
    "w_cleaned_outflows = cleaned_not_matching.copy()\n",
    "#w_cleaned_outflows = cleaned_outflows.copy()\n",
    "\n",
    "def add_text(memo, added_tokens):\n",
    "    memo += ''.join(added_tokens)\n",
    "    return memo\n",
    "\n",
    "def whole_dollar_amount(amount):\n",
    "    if amount % 1 == 0:\n",
    "        return ' <W_D>'\n",
    "    return ''\n",
    "\n",
    "def day(date):\n",
    "    return f\" <D_{date.day}>\"\n",
    "\n",
    "def month(date):\n",
    "    return f\" <M_{date.month}>\"\n",
    "\n",
    "\n",
    "w_cleaned_outflows['memo'] = w_cleaned_outflows.apply(\n",
    "    lambda row: add_text(row['memo'], \n",
    "                         [whole_dollar_amount(row['amount']), \n",
    "                          day(row['posted_date']),\n",
    "                         month(row['posted_date'])]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflows[inflows['amount'] % 1 == 0]['category'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb44a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflows[inflows['amount'] % 5 == 0]['category'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0866957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete\n",
      "Vectorization complete\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'AUTO_LOAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AUTO_LOAN'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_170/4118447623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label encoding complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'AUTO_LOAN'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    outflows_different['memo'], \n",
    "    outflows_different['category'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "print('Data split complete')\n",
    "\n",
    "# Vectorizing the text data - fit only on training data, transform on test data\n",
    "vectorizer = TfidfVectorizer(max_features=5000, max_df=0.95, min_df=5)\n",
    "X_train = vectorizer.fit_transform(X_train_text)\n",
    "X_test = vectorizer.transform(X_test_text)\n",
    "print('Vectorization complete')\n",
    "\n",
    "# Encoding the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "print('Label encoding complete')\n",
    "\n",
    "# Fitting the Logistic Regression model\n",
    "log_reg = LogisticRegression(solver='saga', max_iter=200, n_jobs=-1)\n",
    "log_reg.fit(X_train, y_train)\n",
    "print('Logistic Regression model trained')\n",
    "\n",
    "# Making predictions and calculating accuracy\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Getting predicted probabilities\n",
    "y_prob = log_reg.predict_proba(X_test)\n",
    "\n",
    "# Calculating ROC-AUC score for each category individually\n",
    "roc_auc_scores = {}\n",
    "for i, category in enumerate(label_encoder.classes_):\n",
    "    y_test_binary = np.where(y_test == i, 1, 0)  # Binary label for the current category\n",
    "    \n",
    "    # Only calculate ROC-AUC if there are both positive and negative samples\n",
    "    if len(np.unique(y_test_binary)) == 2:\n",
    "        roc_auc_scores[category] = roc_auc_score(y_test_binary, y_prob[:, i])\n",
    "    else:\n",
    "        roc_auc_scores[category] = \"Undefined (only one class in y_test)\"\n",
    "\n",
    "# Displaying the ROC-AUC score for each category\n",
    "print(\"ROC-AUC Scores per Category:\")\n",
    "for category, score in roc_auc_scores.items():\n",
    "    print(f\"{category}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de2da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows_different = outflows[outflows['memo'] == outflows['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38542cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f1084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
