model_type: Transformer
model_version: TransformerModel
model_name: distilbert-base-uncased
max_length: 128
num_epochs: 3
batch_size: 32
learning_rate: 2e-5
warmup_ratio: 0.1
text_column: memo
label_column: category