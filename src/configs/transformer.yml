model_type: Transformer
model_version: TransformerModel
model_name: distilbert-base-uncased
max_length: 32
num_epochs: 1
batch_size: 16
learning_rate: 2e-5
warmup_ratio: 0.1
text_column: memo
label_column: category