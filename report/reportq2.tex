\documentclass[12pt,letterpaper]{article}
\usepackage{style/dsc180reportstyle} % import dsc180reportstyle.sty
\usepackage{hyperref} % for URLs
\usepackage{tocloft} % for custom table of contents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Title and Authors
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{DSC Capstone Q2 Written Proposal}

\author{Jevan Chahal\\
  {\tt j2chahal@ucsd.edu} \\\And
  Hillary Chang \\
  {\tt hic001@ucsd.edu} \\\And
  Kurumi Kaneko \\
  {\tt kskaneko@ucsd.edu} \\\And
  Kevin Wong \\
  {\tt kew024@ucsd.edu} \\\And
  Brian Duke \\
  {\tt brian.duke@prismdata.com} \\\And
  Kyle Nero \\
  {\tt kyle.nero@ucsd.edu} \\}

\begin{document}
\maketitle

\begin{abstract}
    \textcolor{Black}{
    The process of capturing what makes a creditor trustworthy or not is especially vital within the confines of bank data, due to the guidelines and ethics of what makes this data usable. Although the quantity of the data is massive, there are only a few available features that are explicitly useful in the confines of machine learning, which calls into question how we should measure customer's trustworthiness towards their creditors. Our methodology details the process of refining bank data into categories using Natural Language Processing, assessing individual's income based on bank data alone, and also measuring their credit worthiness both accurately and efficiently. 
    }
\end{abstract}

\begin{center}
Code: \url{https://github.com/hillarychang/dsc180a-capstone-q1}
\end{center}

\tableofcontents
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Main Contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Broad Problem Statement}
Access to credit is extremely important for people trying to build their lives, whether it is used to buy a house, obtain an education, or handle emergencies. However, traditional credit scoring systems like FICO often exclude key aspects of a person’s financial situation. They heavily rely on static data, such as repayment history or credit utilization, which doesn’t tell the whole story. As a result, certain groups, like young adults or those in underprivileged communities, are disproportionately impacted, affecting their access to financial opportunities.

By analyzing detailed spending and income patterns, we can build a more inclusive and fair scoring system. This approach allows us to move away from rigid models and towards a system that reflects actual financial behavior. Patterns like income consistency, balance trends, and spending habits offer a much comprehensive view of a consumer’s risk profile.

By investing 10 weeks into this project, we can demonstrate how transaction data can lead to fairer credit evaluations, ultimately benefiting both lenders and consumers. The opportunity to replace biased systems with data-driven models is incredibly important for equality for all.


\section{Narrow Problem Statement} Traditional credit scoring models miss important details like income regularity, spending priorities, and how balances change over time. During Quarter 1, we made progress by categorizing transactions and estimating income based on inflows. However, this didn’t address how these features could predict credit risk. We now need to build a scoring model that uses these insights to evaluate consumers fairly.

To solve this, we propose building a credit risk prediction model that relies on transaction-based features. Our methods will include:

\textbf{Dataset Exploration and Baseline Feature Testing:} We will begin by performing exploratory data analysis (EDA) to identify trends in the dataset and evaluate single features, such as total inflows or balance variability, to assess their standalone predictive power and to determine which feature is most predictive of credit risk.

\textbf{Balance and Income Feature Engineering:} We will analyze temporal patterns in income and balance trends by using moving averages, standard deviations, and recurrence analysis to identify consistency. For instance, we will calculate features like "mean balance over the last three months" and "income variability over time" using time-series statistical methods. By sampling “good” and “bad” consumers, we will use K-means clustering to uncover key behavioral patterns.

\textbf{Category-Based Features:} We will categorize spending and income transactions into groups like essentials and non-essentials based on transaction memos and amounts. Using NLP techniques like TF-IDF or BERT-based embeddings, we will further refine these categories to derive features like "percent of income spent on essentials" or "ratio of paycheck to discretionary spending."

\textbf{Temporal Attributes and Comprehensive Feature Set:} We will engineer attributes that capture dynamic changes in spending, income, and balances over time. This includes calculating balance recovery times, peak-to-trough differences, and seasonality patterns using Fourier transforms or seasonal decomposition of time series. The goal is to create at least 100 features that capture short-term and long-term financial behavior.

\textbf{Feature Selection:} To optimize the model and reduce overfitting, we will apply feature selection techniques such as Lasso regression. These methods will allow us to narrow down our feature set to the top 40 predictors by ranking their importance based on model performance.

\textbf{Model Training and Explanation:} We will train and evaluate machine learning models using Logistic Regression, Random Forest, and Gradient Boosted Trees like XGBoost. We will generate reason codes for each consumer that highlight why they were classified as risky or non-risky. These codes will help us analyze the distribution of common reasons across the population.

The methods we’re proposing build directly on the gaps identified in Quarter 1. While categorization and income estimation provided insights into financial behavior, they didn’t connect these patterns to credit risk outcomes. By bridging this gap with feature engineering, temporal analysis, and interpretable machine learning models, we can create a practical scoring tool that is both fair and scalable. This solution is urgently needed to address systemic issues in credit access and to demonstrate how modern data techniques can improve financial systems.


\section{Primary Output}
This project will deliver the following results:
\begin{enumerate}
    \item \textbf{Comprehensive Report:} A comprehensive report explaining our methods, results, and the impact of transaction-based features on credit risk prediction. This report will also address fairness and interpretability considerations.
    \item \textbf{Prediction CSV File:} A file containing credit risk scores for each consumer in the holdout dataset, along with three reason codes per prediction. These reason codes will explain why each consumer was classified as risky or non-risky, ensuring transparency.
    \item \textbf{Presentation Poster:} A poster summarizing the project’s methodology, results, etc. visually. This will be useful for presenting our findings to stakeholders in a concise way.
\end{enumerate}

\end{document}
